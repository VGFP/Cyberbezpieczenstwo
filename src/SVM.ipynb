{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b73323",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install sklearn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, confusion_matrix, recall_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb2a9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How big is train dataset ?\n",
    "train_test_ratio = 0.039\n",
    "np.random.RandomState(seed=42)\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), '..',  'dataset'))\n",
    "\n",
    "names = pd.read_csv(os.path.join(data_path, 'NUSW-NB15_features_v2.csv'))['Name'].tolist()\n",
    "\n",
    "frames = []\n",
    "\n",
    "frames.append(pd.read_csv(os.path.join(data_path, \"UNSW-NB15_1.csv\"), names=names))\n",
    "# Uncomment to load all csv\n",
    "frames.append(pd.read_csv(os.path.join(data_path, \"UNSW-NB15_2.csv\"), names=names))\n",
    "frames.append(pd.read_csv(os.path.join(data_path, \"UNSW-NB15_3.csv\"), names=names))\n",
    "frames.append(pd.read_csv(os.path.join(data_path, \"UNSW-NB15_4.csv\"), names=names))\n",
    "\n",
    "df = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "mask = np.random.rand(len(df)) < train_test_ratio\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "\n",
    "# Clear memory\n",
    "del df\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef17d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Info about data types and columns\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in columns\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many attacks and normal records do we have ?\n",
    "train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = train.corr()['Label']\n",
    "\n",
    "plt.bar(correlation.keys(), correlation.tolist())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = correlation.to_dict()\n",
    "correlation_treshold = 0.2\n",
    "\n",
    "# Return column names where correlation is greater or equal than threshold\n",
    "column_names = [key for key, value in corr_dict.items() if abs(value) >= correlation_treshold]\n",
    "column_names.remove('Label')\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train[column_names])\n",
    "y_train = train['Label']\n",
    "# del train\n",
    "\n",
    "X_test = scaler.transform(test[column_names])\n",
    "y_test = test['Label']\n",
    "# del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eecd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'logreg': LogisticRegression(),\n",
    "    'forest': RandomForestClassifier(),\n",
    "    'gradboost': GradientBoostingClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'mlp': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "conf_matrix = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append([name, f1, prec, rec, acc])\n",
    "    conf_matrix[name] = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "df_results = pd.DataFrame(results, columns=['model', 'f1', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = df_results.round(4)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# save reg_data results to pickle file\n",
    "with open('reg_data_results.pickle', 'wb') as f:\n",
    "    pickle.dump(reg_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in conf_matrix.items():\n",
    "    conf_matrix[key] = item / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 6), sharey=True, sharex=True, constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (model, cm) in enumerate(conf_matrix.items()):\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(cm, ax=ax, annot=True, square=True, cbar=False,\n",
    "                fmt=\".2%\", vmin=0, vmax=cm.sum().sum(), annot_kws={'size': 13})\n",
    "    \n",
    "    ax.set_title(model, fontsize=16)\n",
    "    ax.margins(0)\n",
    "    ax.grid(False)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel('true label')\n",
    "    ax.set_xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d46a4",
   "metadata": {},
   "source": [
    "Opisac dane jak go przygotowali≈õmy.\n",
    "Algorytmy\n",
    "opisac wyniki dla SL i OCSVM\n",
    "Dalsze prace\n",
    "Kilka zdan o wynikach w porownaniu do danych zanonimizowanych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1603d",
   "metadata": {},
   "source": [
    "## Anonymized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is train dataset ?\n",
    "train_test_ratio = 0.039\n",
    "np.random.RandomState(seed=42)\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), '..',  'dataset'))\n",
    "\n",
    "cats = [\"srcip\",\"dstip\",\"proto\",\"state\",\"dur\",\"sbytes\",\"dbytes\",\"sttl\",\"dttl\",\"sloss\",\"dloss\",\"service\",\"Sload\",\"Dload\",\"Spkts\",\"Dpkts\",\"swin\",\"dwin\",\"stcpb\",\"dtcpb\",\"smeansz\",\"dmeansz\",\"trans_depth\",\"res_bdy_len\",\"Sjit\",\"Djit\",\"Sintpkt\",\"Dintpkt\",\"tcprtt\",\"synack\",\"ackdat\",\"is_sm_ips_ports\",\"ct_state_ttl\",\"ct_flw_http_mthd\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_srv_src\",\"ct_srv_dst\",\"ct_dst_ltm\",\"ct_src_ ltm\",\"ct_src_dport_ltm\",\"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"attack_cat\",\"Label\"]\n",
    "\n",
    "# names = pd.read_csv(os.path.join(data_path, 'NUSW-NB15_features_v2.csv'))['Name'].tolist()\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, \"UNSW-NB15_1_anonymized_no_col_names.csv\"), names=cats)\n",
    "\n",
    "mask = np.random.rand(len(df)) < train_test_ratio\n",
    "train = df[mask]\n",
    "test = df[~mask]\n",
    "\n",
    "# Clear memory\n",
    "del df\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = train.corr()['Label']\n",
    "\n",
    "plt.bar(correlation.keys(), correlation.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = correlation.to_dict()\n",
    "correlation_treshold = 0.2\n",
    "\n",
    "# Return column names where correlation is greater or equal than threshold\n",
    "column_names = [key for key, value in corr_dict.items() if abs(value) >= correlation_treshold]\n",
    "column_names.remove('Label')\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b78030",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'logreg': LogisticRegression(),\n",
    "    'forest': RandomForestClassifier(),\n",
    "    'gradboost': GradientBoostingClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'mlp': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train[column_names])\n",
    "y_train = train['Label']\n",
    "# del train\n",
    "\n",
    "X_test = scaler.transform(test[column_names])\n",
    "y_test = test['Label']\n",
    "# del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ba38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "conf_matrix = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append([name, f1, prec, rec, acc])\n",
    "    conf_matrix[name] = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "df_results = pd.DataFrame(results, columns=['model', 'f1', 'precision', 'recall', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.round(4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in conf_matrix.items():\n",
    "    conf_matrix[key] = item / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 6), sharey=True, sharex=True, constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (model, cm) in enumerate(conf_matrix.items()):\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(cm, ax=ax, annot=True, square=True, cbar=False,\n",
    "                fmt=\".2%\", vmin=0, vmax=cm.sum().sum(), annot_kws={'size': 13})\n",
    "    \n",
    "    ax.set_title(model, fontsize=16)\n",
    "    ax.margins(0)\n",
    "    ax.grid(False)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel('true label')\n",
    "    ax.set_xlabel('predicted label')\n",
    "\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a34621",
   "metadata": {},
   "source": [
    "# One Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cbe9c",
   "metadata": {},
   "source": [
    "Getting highly correlated features to reduce time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = correlation.to_dict()\n",
    "correlation_treshold_for_OCSVM = 0.6\n",
    "\n",
    "# Return column names where correlation is greater or equal than threshold\n",
    "column_names_for_OCSVM = [key for key, value in corr_dict.items() if abs(value) >= correlation_treshold_for_OCSVM]\n",
    "column_names_for_OCSVM.remove('Label')\n",
    "column_names_for_OCSVM = [  'dwin',\n",
    "                            'stcpb',\n",
    "                            'dtcpb'] # changed for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f50884",
   "metadata": {},
   "source": [
    "## OCSVM trained on full set of data\n",
    "\n",
    "OCSVM model trained on both attack and not attack data. It should create a model that labels attacks as outliers (gives them -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm One Class\n",
    "\n",
    "# Load data\n",
    "x_train = train[column_names_for_OCSVM]\n",
    "x_test = test[column_names_for_OCSVM]\n",
    "\n",
    "one_class_svm = OneClassSVM(gamma='auto')\n",
    "output = one_class_svm.fit_predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66283d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = copy.deepcopy(output)\n",
    "\n",
    "for count, out in enumerate(output):\n",
    "    if out == -1:\n",
    "        new_output[count] = 1\n",
    "    else:\n",
    "        new_output[count] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9875fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_output = train['Label']\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(new_output, y_train_output).ravel()\n",
    "print(f\"TP: {tp}\")\n",
    "print(f\"TN: {tn}\")\n",
    "print(f\"FP: {fp}\")\n",
    "print(f\"FN: {fn} <- attacks not detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b5807",
   "metadata": {},
   "source": [
    "Model does not detect attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05315428",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_output = one_class_svm.predict(test[column_names_for_OCSVM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8089c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good train data (no attacks)\n",
    "\n",
    "x_train_no_attacts = train[train['Label'] == 0]\n",
    "\n",
    "x_train_no_attacts = x_train_no_attacts[column_names_for_OCSVM]\n",
    "\n",
    "one_class_svm_only_good_data = OneClassSVM(gamma='auto')\n",
    "output_only_good_data = one_class_svm_only_good_data.fit(x_train_no_attacts)\n",
    "\n",
    "x_train_no_attacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c660a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test OCSVM that was trained only on good data\n",
    "\n",
    "y_test_output_good_data = one_class_svm_only_good_data.predict(test[column_names_for_OCSVM].head(10000))\n",
    "\n",
    "y_test_output_good_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83356a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test_output_good_data = copy.deepcopy(y_test_output_good_data)\n",
    "\n",
    "for count, out in enumerate(y_test_output_good_data):\n",
    "    if out == -1:\n",
    "        new_y_test_output_good_data[count] = 1\n",
    "    else:\n",
    "        new_y_test_output_good_data[count] = 0\n",
    "print(len(new_y_test_output_good_data))\n",
    "print(np.sum(new_y_test_output_good_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_good_data = test['Label'].head(10000)\n",
    "tn, fp, fn, tp = confusion_matrix(y_label_good_data, new_y_test_output_good_data).ravel()\n",
    "print(f\"TP: {tp}\")\n",
    "print(f\"TN: {tn}\")\n",
    "print(f\"FP: {fp}\")\n",
    "print(f\"FN: {fn} <- attacks not detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b5b45",
   "metadata": {},
   "source": [
    "### Results:\n",
    "One Class SVM for tested features does not detect attacks and is not suitable for detecting network attacks.\n",
    "It also takes a lot of time to train for higher number of features. \n",
    "To create a better OCSVM model we need to find features where distance between attacks and not attacks is highest. That would improve model's accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcc8378988483142d0d745233416534782bb7caf8f6433b4451eca61fdf27a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
